# Ajustando modelos con `parsnip`

**Objetivos de Aprendizaje:**

- Identificar formas en que **interfaces de modelos pueden diferir.**
- **Especificar un modelo** en `{parsnip}`.
- **Ajustar un modelo** con `parsnip::fit()` y `parsnip::fit_xy()`.
- Describir como `{parsnip}` **generaliza los argumentos de modelos.**
- Usar `broom::tidy()` para **convertir objetos de modelos en estructuras _tidy_.**
- Usar `dplyr::bind_cols()` y los métodos `predict()` de `{parsnip}` para **crear predicciones _tidy_.**
- **Encontrar interfaces a otros modelos** en paquetes adyacentes a `{parsnip}` (paquetes del universo `tidymodels`).

<details>
  <summary> Mapa de Modelado </summary>
  
  ![flujo de modelado](images/modeling_map.png)

- __Configuración para el capítulo__

```{r set-up-07, warning=FALSE, message=FALSE}
# cargar parsnip, recipes, rsample, broom...
library(tidymodels)
library(AmesHousing)

# cargar los datos
data(ames)

# aplicar el logaritmo base 10 a price
ames <- dplyr::mutate(ames, Sale_Price = log10(Sale_Price))

# subconjuntos de entrenamiento y prueba
set.seed(123)
ames_split <- rsample::initial_split(ames, prob = 0.80, strata = Sale_Price)
ames_train <- rsample::training(ames_split)
ames_test  <- rsample::testing(ames_split)
```  

</details>




<br>

## Crear un modelo


### Diferentes Interfaces de Modelado

  
![diferentes interfaces](images/interfaces-meme.jpg)



<br>

- Interfaces de Modelos
  - Diferentes Implementaciones = Diferentes Interfaces
  - _Regresión Lineal_ puede ser implementada en varias maneras
    - Mínimos Cuadrados Ordinarios (MCO) / _Ordinary Least Squares_
    - Regresión Lineal Regularizada / _Regularized Linear Regression_
    - ...

<br>

- __{stats}__
  - toma una fórmula
  - usa un `data.frame`

```{r lm-interface, eval=FALSE}
lm(formula, data, ...)
```

<br>


- __{glmnet}__ 
  - tiene una interfaz `x`/`y`
  - usa una matriz

```{r glmnet-interface, eval=FALSE}
glmnet(x = matrix, y = vector, family = "gaussian", ...)
```

<br>
<br>

### Especificación del Modelo

![especificación del modelo](images/model_specification_process.png)

- __{tidymodels}/{parsnip}__ 
  - La filosofía es unificar y crear interfases más predecibles.
    - Especificar el tipo de modelo (e.g. regresión lineal, bosques aleatorios, ...)
      - `linear_reg()`
      - `rand_forest()`
    - Especificar el "motor" (i.e. paquete con la implementación del algoritmo)
      - `set_engine("paquete con la implementación")`
    - Declarar el modo (e.g. clasificación vs regresión lineal)
      - usa esto cuando el modelo puede ejecutar ambas clasificación y regresión lineal
      - `set_mode("regression")`
      - `set_mode("classification")`
    
  
<br>

- __Trayendo todo junto__

```{r model-spec}
lm_model_spec <- 
  parsnip::linear_reg() %>% # especificar el modelo
  parsnip::set_engine("lm") # especificar el motor


lm_model_spec
```


<br>
<br>


### Ajustando el Modelo

Usando la especificación de modelo previamente definida


<br>

- `fit()`
  - cualquier variable nominal o categórica será separada en _variables ficticias_
  - la _mayoría_ de métodos que usan una fórmula hacen esto mismo
<!-- - _most_ formula methods also turn do the same thing -->
- `fit_xy`
  - retrasa la creación de _variables ficticias_ y tiene una función de modelo subyacente
  

```{r model-fit}
# crear un ajuste de modelo usando una fórmula
lm_form_fit <- 
  lm_model_spec %>% 
  parsnip::fit(Sale_Price ~ Longitude + Latitude, data = ames_train)

# crear un ajuste de modelo usando x/y
lm_xy_fit <- 
  lm_model_spec %>% 
  parsnip::fit_xy(
    x = ames_train %>% dplyr::select(Longitude, Latitude),
    y = ames_train %>% dplyr::pull(Sale_Price)
  )
```

<br>
<br>


### Argumentos de Modelo Generalizados

- Como las interfases de modelo que varian, los parámetros de los modelos también varian de implementación a implementación
- Dos niveles de argumentos de modelos
  - __argumentos principales__ - Parámetros alineados con _vehículos matemáticos_
  - __argumentos de motor__ - Parámetros alineados con el paquete de implementación del algoritmo matemático


```{r package-param-comparisions, echo=FALSE}
tribble(
 ~argument,     ~ranger,  ~randomForest, ~sparklyr,
  "sampled predictors",    "mtry", "mtry", "feature_subset_strategy",
  "trees",    "num.tress", "ntree", "num_trees",
  "data points to split",    "min.node.size", "nodesize", "min_instances_per_node"
) %>% 
  knitr::kable()
```

<br>

  

```{r parsnip-param-comparisions, echo=FALSE}
tribble(
 ~argument,              ~parsnip,
  "sampled predictors",  "mtry",  
  "trees",               "trees",
  "data points to split","min_n"  
) %>% 
  knitr::kable()
```



<br>


![`{parsnip}` en action](images/parsnip_meme.jpg)

<br>


+ La función `translate()` provee el mapeo desde la interfaz de `{parsnip}` a cada uno de los paquetes de implementación de los algoritmos. 
<!-- the mapping from the parsnips interface to the each individual package's implementation of the algorithm. -->

```{r model-package-differences}
# stats implementation
parsnip::linear_reg() %>% 
  parsnip::set_engine("lm") %>% 
  parsnip::translate()


# glmnet implementation
parsnip::linear_reg(penalty = 1) %>% 
  parsnip::set_engine("glmnet") %>% 
  parsnip::translate()
```


## Use Model results



Now that we have a fitted model we will need to pull some summary information from it we will use two extremely _fun_ functions from the `{broom}` package to help us out (`tidy()` & `glance()`). 


+ `tidy()` - Has a bunch of versatility, but for our context it can take our model object and return our model coefficients into a nice tibble.

```{r broom-tidy}
broom::tidy(lm_form_fit) %>% 
  knitr::kable()
```

<br>

+ `glance()` - allows us in this context to convert our model's summary statistics into a `tibble`

```{r broom-glance}
broom::glance(lm_form_fit) %>% 
  knitr::kable()
```




## Make Predictions


![](images/crystal_ball.png)


- __Rules to Live by__: 
  - Returns a tibble
  - Column names are ... erh Predictable
  - Return the same number of rows as are in the data set
    - some predict functions omit observations with `NA` values.  Which is great if that's what you intend, but if you aren't expecting that behavior you would have to find out the hard way.



```{r predict-new-data}
# create example test set
ames_test_small <- ames_test %>% slice(1:5)

# predict on test set
predict(lm_form_fit, new_data = ames_test_small) %>% 
  knitr::kable()
```

<br>

- Combining `bind_cols` with our predict function we can merge our predictions back to the test set.

```{r combine-07}
# add predictions together with actuals
ames_test_small %>%
  select(Sale_Price) %>%
  bind_cols(predict(lm_form_fit, ames_test_small)) %>%
  # Add 95% prediction intervals to the results:
  bind_cols(predict(lm_form_fit, ames_test_small, type = "pred_int")) %>% 
  knitr::kable()
```

## {tidymodels}-Adjacent Packages

- Opinions can be shared, other modeling packages can use the same opinion to replicate a workflow. The `{discrim}`^[Discrim Package [Link](https://github.com/tidymodels/discrim)] package adds a new set of mathematical models to our arsenal of tools.
  - `discrim_flexible()` `%>%` - Mathematical Model or if we are using my terrible analogy the car body
    - `set_engine("earth")` - The package we want to approximate our discriminat analysis

```{r adjacent-packages, warning=FALSE, message=FALSE}
# devtools::install_github("tidymodels/discrim") # to install
# load package
library(discrim)

# create dummy data
parabolic_grid <-
  expand.grid(X1 = seq(-5, 5, length = 100),
              X2 = seq(-5, 5, length = 100))

# fit model from discrim
fda_mod <-
  discrim_flexible(num_terms = 3) %>% 
  set_engine("earth") %>%
  fit(class ~ ., data = parabolic)

# assigning predictions to data frame
parabolic_grid$fda <-
  predict(fda_mod, parabolic_grid, type = "prob")$.pred_Class1

# plotting prediction
library(ggplot2)
ggplot(parabolic, aes(x = X1, y = X2)) +
  geom_point(aes(col = class), alpha = .5) +
  geom_contour(data = parabolic_grid, aes(z = fda), col = "black", breaks = .5) +
  theme_bw() +
  theme(legend.position = "top") +
  coord_equal()
```


## Resumen

- __Crear una Interfaz Común__ 
  - Todos los modelos están compuestos por algunos componentes principales
    - modelos matemáticos
    - implementación de "motores"
    - modo si es requerido
    - Argumentos
      - Principal - especificación del algoritmo (árboles, número de atributos, penalidad)
      - Motor - Especificación del paquete/motor (e.g. verbose, num.threads, ...)
  - __Comportamiento Predictivo__
    - `tibble` como entrada, `tibble` como salida
    - igual número de observaciones regresadas por `predict()`

## Videos de las Reuniones

### Cohorte 1

`r knitr::include_url("https://www.youtube.com/embed/")`

<details>
  <summary> Meeting chat log </summary>
  
```

```
</details>
